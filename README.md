# AI Document Assistant using Retrieval-Augmented Generation (RAG)

## ğŸ“Œ Project Overview

The **AI Document Assistant** is an end-to-end Retrieval-Augmented Generation (RAG) application that converts video content into searchable knowledge and enables users to ask natural language questions to get accurate, context-aware answers. This project demonstrates practical use of **LLMs, embeddings, vector databases, and information retrieval**.

This project is **ATS-friendly** and suitable for showcasing skills in **Data Science, Machine Learning, NLP, and LLM-based application development**.

---

## ğŸ¯ Problem Statement

Large video and document content is difficult to search and query efficiently. Traditional keyword search fails to capture semantic meaning.

**Solution:**
Build a system that:

* Converts videos into text
* Stores semantic embeddings
* Retrieves relevant context using vector search
* Generates precise answers using an LLM

---

## ğŸš€ Key Features

* Video to audio conversion
* Automatic speech-to-text transcription using OpenAI Whisper
* Text chunking and semantic embeddings
* Fast similarity search using FAISS
* Context-aware answer generation using LLM (RAG architecture)
* Modular and scalable pipeline

---

## ğŸ§  Architecture (RAG Pipeline)

1. **Ingestion**: Video â†’ Audio â†’ Transcript
2. **Embedding Store**: Transcript chunking â†’ Vector embeddings â†’ FAISS index
3. **Retriever**: Semantic search for top-k relevant chunks
4. **Generator**: LLM generates answers using retrieved context

---

## ğŸ› ï¸ Technologies Used

* **Python**
* **OpenAI Whisper** (Speech-to-Text)
* **Sentence Transformers (all-MiniLM-L6-v2)**
* **FAISS** (Vector Database)
* **OpenAI API** (LLM for answer generation)
* **MoviePy** (Video processing)
* **NumPy**

---

## ğŸ“‚ Project Structure

```
AI-Document-Assistant-using-RAG/
â”‚
â”œâ”€â”€ videos/                # Input video files (.mp4)
â”œâ”€â”€ audio/                 # Extracted audio files
â”œâ”€â”€ transcripts/           # Generated transcripts (.txt)
â”œâ”€â”€ embeddings/            # FAISS index and embeddings
â”‚   â”œâ”€â”€ faiss.index
â”‚   â””â”€â”€ chunks.npy
â”‚
â”œâ”€â”€ ingest.py              # Phase 1: Video â†’ Audio â†’ Transcript
â”œâ”€â”€ embed_store.py         # Phase 2: Text chunking & embedding creation
â”œâ”€â”€ retriever.py           # Phase 3: Semantic retrieval using FAISS
â”œâ”€â”€ rag_pipeline.py        # Phase 4: RAG (Retriever + LLM)
â”œâ”€â”€ app.py                 # Phase 5: UI layer (Streamlit web application)
â”œâ”€â”€ requirements.txt       # Project dependencies
â”œâ”€â”€ setup.py               # Phase 0: Initial project setup & environment validation
â””â”€â”€ README.md
```

## âš™ï¸ Installation & Setup
````
```bash
# Clone repository
git clone https://github.com/your-username/AI-Document-Assistant-using-RAG.git
cd AI-Document-Assistant-using-RAG
---
---
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
---
---
# Install dependencies
pip install -r requirements.txt
````

Set your OpenAI API key:

```bash
export OPENAI_API_KEY="your_api_key"  # Windows: setx OPENAI_API_KEY "your_api_key"
```

---

## â–¶ï¸ How to Run (Phase-wise Execution)

### ğŸ”¹ Step 0: Initial Setup

```bash
python setup.py
```

* Validates environment
* Checks required folders
* Ensures dependencies are installed

---

### ğŸ”¹ Phase 1: Video to Text (Ingestion)

```bash
python ingest.py
```

* Converts video to audio
* Transcribes audio using Whisper
* Saves transcripts to `transcripts/`

---

### ğŸ”¹ Phase 2: Embedding & Vector Store Creation

```bash
python embed_store.py
```

* Splits transcripts into chunks
* Generates embeddings using Sentence Transformers
* Stores vectors in FAISS index

---

### ğŸ”¹ Phase 3: Semantic Retrieval (Optional Test)

```bash
python retriever.py
```

* Retrieves top-k relevant chunks
* Useful for debugging and validation

---

### ğŸ”¹ Phase 4: RAG Pipeline (LLM Answering)

```bash
python rag_pipeline.py
```

* Retrieves context using FAISS
* Generates answers using LLM

---

### ğŸ”¹ Phase 5: UI Layer (Streamlit App)

```bash
streamlit run app.py
```

* User-friendly web interface
* Allows users to ask questions interactively

---

## ğŸ“ˆ Results & Impact

* Enables semantic search over unstructured video content
* Improves answer accuracy using context-aware retrieval
* Demonstrates real-world RAG implementation
* Scalable for documents, PDFs, meetings, lectures, and tutorials

---

## ğŸ“Œ Use Cases

* Educational video Q&A
* Corporate training material search
* Meeting and lecture summarization
* Knowledge base assistants

---

## ğŸ”® Future Enhancements

* Streamlit-based web UI
* Support for PDFs and documents
* Metadata-based filtering
* Caching and performance optimization
* Deployment using Docker

---

## ğŸ‘©â€ğŸ’» Author

**Shruti Adsul**
Aspiring Data Analyst | ML & LLM Enthusiast

---

## â­ Call to Action

If you found this project helpful:

* â­ Star the repository
* ğŸ´ Fork it
* ğŸ’¬ Share feedback

